# core/image_pdf_translator.py

import asyncio
from pathlib import Path
from typing import Optional
from loguru import logger
from pypdf import PdfReader, PdfWriter

# å„æ¨¡å—å¯¼å…¥ï¼ˆä¿æŒåŸå‡½æ•°ä¸å˜ï¼‰
from .mineru_engine import run_single_pdf
from .split_json_extractor import extract_leaf_blocks_from_file
from .json_translator import translate_single_json_file
from .html_to_pdf_converter import convert_single_html_to_pdf
from .blur_pdf_from_translated import generate_censored_pdf
from .pdf_final_merger import merge_all_final_pdfs
from .json_to_html_renderer import render_json_to_html
from core.pdf_compression import compress_pdf_structure_only

class PipelineMessage:
    def __init__(self, chunk_path: Path):
        self.chunk_path = chunk_path
        self.chunk_stem = chunk_path.stem
        self.pdf_type: Optional[str] = None
        self.mineru_output: Optional[dict] = None
        self.leaf_block_path: Optional[Path] = None
        self.translated_path: Optional[Path] = None
        self.html_path: Optional[Path] = None
        self.pdf_path: Optional[Path] = None          # ç”¨äºæœ€ç»ˆç¿»è¯‘ PDF
        self.censored_pdf_path: Optional[Path] = None  # âœ… æ–°å¢ï¼šæ¶‚ç™½åçš„ PDF è·¯å¾„
        self.error: Optional[str] = None


async def stage_splitter(
    pdf_path: Path,
    workdir: Path,
    chunk_size: int,
    output_queue: asyncio.Queue,
    pdf_type: str
):
    """
    Stage 1: åˆ†å‰² PDFï¼Œæ¯ç”Ÿæˆä¸€ä¸ª chunk å°±å‘é€æ¶ˆæ¯ã€‚
    """
    chunks_dir = workdir / "chunks"
    chunks_dir.mkdir(exist_ok=True)
    reader = PdfReader(str(pdf_path))
    total_pages = len(reader.pages)
    base_name = pdf_path.stem

    for i in range(0, total_pages, chunk_size):
        start = i
        end = min(i + chunk_size, total_pages)
        chunk_file = chunks_dir / f"{base_name}_part_{(i // chunk_size) + 1:03d}.pdf"

        if not chunk_file.exists():
            writer = PdfWriter()
            for page_idx in range(start, end):
                writer.add_page(reader.pages[page_idx])
            with open(chunk_file, "wb") as f:
                writer.write(f)

        msg = PipelineMessage(chunk_file)
        msg.pdf_type = pdf_type
        await output_queue.put(msg)
        logger.info(f"âœ‚ï¸ åˆ†å‰²å®Œæˆ: {chunk_file.name}")

    logger.info("âœ… åˆ†å‰²é˜¶æ®µå®Œæˆ")
    await output_queue.put(None)  # å‘é€ç»“æŸä¿¡å·


async def stage_mineru_processor(
    input_queue: asyncio.Queue,
    output_queue: asyncio.Queue,
    mineru_output_dir: Path,
    pdf_type: str,
    concurrency: int,
    mineru_api_key = None,
    mineru_base_url= None,
):
    """
    Stage 2: å¹¶å‘è¿è¡Œ MinerUï¼Œå¤„ç†æ¯ä¸ª chunkã€‚
    """
    semaphore = asyncio.Semaphore(concurrency)
    running_tasks = []
    end_signal_received = False

    async def process(msg: PipelineMessage):
        async with semaphore:
            try:
                # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œè€—æ—¶çš„åŒæ­¥å‡½æ•°
                loop = asyncio.get_running_loop()
                result = await loop.run_in_executor(
                    None,
                    run_single_pdf,
                    str(msg.chunk_path),
                    str(mineru_output_dir),
                    str(pdf_type),                    
                    str(mineru_api_key),
                    str(mineru_base_url),  
                )

                if not result.get("success"):
                    msg.error = f"MinerU failed: {result.get('error', 'Unknown error')}"
                    logger.error(f"âŒ MinerU å¤±è´¥: {msg.chunk_path.name} | {msg.error}")
                    return

                msg.mineru_output = result
                await output_queue.put(msg)
                logger.info(f"âœ… MinerU å®Œæˆ: {msg.chunk_path.name}")

            except Exception as e:
                msg.error = f"MinerU exception: {e}"
                logger.error(f"âŒ MinerU å¼‚å¸¸: {msg.chunk_path.name} | {e}")
            finally:
                input_queue.task_done()

    # Step 1: æ¶ˆè´¹ input_queueï¼Œåˆ›å»ºä»»åŠ¡
    while not end_signal_received:
        msg = await input_queue.get()
        if msg is None:
            input_queue.task_done()
            end_signal_received = True
            break
        task = asyncio.create_task(process(msg))
        running_tasks.append(task)

    # Step 2: ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å¤„ç†å®Œæˆï¼ˆæ‰€æœ‰ task å¯åŠ¨å®Œæ¯•ï¼‰
    await input_queue.join()

    # Step 3: ç­‰å¾…æ‰€æœ‰å·²åˆ›å»ºçš„ä»»åŠ¡çœŸæ­£æ‰§è¡Œå®Œæ¯•
    if running_tasks:
        await asyncio.gather(*running_tasks, return_exceptions=True)

    # Step 4: å‘é€ç»“æŸä¿¡å·
    await output_queue.put(None)
    logger.info("âœ… MinerU å¤„ç†é˜¶æ®µå®Œæˆ")


async def stage_leaf_extractor(
    input_queue: asyncio.Queue,
    output_queue: asyncio.Queue,
    pdf_type: str
):
    """
    Stage 3: æå–å¶çº§å—ï¼ˆ_middle.json â†’ _leaf_blocks.jsonï¼‰
    """
    end_signal_received = False
    
    while not end_signal_received:
        msg: PipelineMessage = await input_queue.get()
        if msg is None:
            input_queue.task_done()
            end_signal_received = True
            break

        if msg.error:
            input_queue.task_done()
            continue

        middle_json = Path(msg.mineru_output["output_path"])
        leaf_json = middle_json.parent / f"{msg.chunk_stem}_leaf_blocks.json"

        # âœ… è·³è¿‡é€»è¾‘ï¼šå¦‚æœ leaf_blocks.json å·²å­˜åœ¨ï¼Œç›´æ¥è·³è¿‡æå–
        if leaf_json.exists():
            msg.leaf_block_path = leaf_json
            await output_queue.put(msg)
            logger.info(f"ğŸ” å¶å—æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡æå–: {leaf_json.name}")
            input_queue.task_done()
            continue

        if not middle_json.exists():
            msg.error = f"Missing _middle.json: {middle_json}"
            logger.error(f"âŒ ç¼ºå¤±æ–‡ä»¶: {msg.error}")
            input_queue.task_done()
            continue

        try:
            loop = asyncio.get_running_loop()
            success = await loop.run_in_executor(
                None,
                extract_leaf_blocks_from_file,
                middle_json,
                pdf_type
            )

            if success:
                msg.leaf_block_path = leaf_json
                await output_queue.put(msg)
                logger.info(f"ğŸ” å¶å—æå–å®Œæˆ: {leaf_json.name}")
            else:
                msg.error = f"Extract leaf blocks failed: {middle_json}"
                logger.error(f"âŒ å¶å—æå–å¤±è´¥: {msg.error}")
        except Exception as e:
            msg.error = f"Exception during leaf extraction: {e}"
            logger.error(f"âŒ å¶å—æå–å¼‚å¸¸: {msg.error}")

        input_queue.task_done()

    await output_queue.put(None)
    logger.info("âœ… å¶å—æå–é˜¶æ®µå®Œæˆ")

async def stage_translator(
    input_queue: asyncio.Queue,
    output_queue: asyncio.Queue,
    target_lang: str,
    api_key: str,
    base_url: str,
    model_name: str,
    concurrency: int
):
    """
    Stage 4: ç¿»è¯‘ _leaf_blocks.json â†’ _translated.json
    âœ… æ–°å¢ï¼šè‹¥ _translated.json å·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡ç¿»è¯‘
    """
    semaphore = asyncio.Semaphore(concurrency)
    running_tasks = []
    end_signal_received = False

    async def translate(msg: PipelineMessage):
        async with semaphore:
            try:
                output_file = msg.leaf_block_path.parent / f"{msg.leaf_block_path.stem.replace('_leaf_blocks', '_translated')}.json"

                # âœ… è·³è¿‡é€»è¾‘ï¼šå¦‚æœç¿»è¯‘ç»“æœå·²å­˜åœ¨ï¼Œç›´æ¥å¤ç”¨
                if output_file.exists():
                    msg.translated_path = output_file
                    await output_queue.put(msg)
                    logger.info(f"ğŸŒ ç¿»è¯‘æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ç¿»è¯‘: {output_file.name}")
                    return

                translated_path = await translate_single_json_file(
                    input_path=msg.leaf_block_path,
                    output_path=output_file,
                    target_lang=target_lang,
                    api_key=api_key,
                    base_url=base_url,
                    model_name=model_name,
                    concurrency=concurrency
                )
                msg.translated_path = Path(translated_path)
                await output_queue.put(msg)
                logger.info(f"ğŸŒ ç¿»è¯‘å®Œæˆ: {output_file.name}")
            except Exception as e:
                msg.error = f"Translation failed: {e}"
                logger.error(f"âŒ ç¿»è¯‘å¤±è´¥: {msg.leaf_block_path} | {e}")
            finally:
                input_queue.task_done()

    while not end_signal_received:
        msg = await input_queue.get()
        if msg is None:
            input_queue.task_done()
            end_signal_received = True
            break
        if not msg.error:
            task = asyncio.create_task(translate(msg))
            running_tasks.append(task)
        else:
            input_queue.task_done()

    # ç­‰å¾…æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡å®Œæˆ
    if running_tasks:
        await asyncio.gather(*running_tasks, return_exceptions=True)
        
    await output_queue.put(None)
    logger.info("âœ… ç¿»è¯‘é˜¶æ®µå®Œæˆ")


async def stage_blur_processor(
    input_queue: asyncio.Queue,
    output_queue: asyncio.Queue
):
    """
    Stage 4.5: ä¸ºæ¯ä¸ª chunk ç”Ÿæˆæ¶‚ç™½ PDFï¼ˆ_censored.pdfï¼‰
    """
    end_signal_received = False
    
    while not end_signal_received:
        msg: PipelineMessage = await input_queue.get()
        if msg is None:
            input_queue.task_done()
            end_signal_received = True
            break

        if msg.error:
            input_queue.task_done()
            continue

        origin_pdf = msg.chunk_path
        translated_json = msg.translated_path
        censored_pdf = msg.translated_path.parent / f"{msg.chunk_stem}_censored.pdf"

        # âœ… è·³è¿‡é€»è¾‘ï¼šå¦‚æœæ¶‚ç™½ PDF å·²å­˜åœ¨ï¼Œç›´æ¥è·³è¿‡
        if censored_pdf.exists():
            msg.censored_pdf_path = censored_pdf
            await output_queue.put(msg)
            logger.info(f"ğŸ©¹ æ¶‚ç™½PDFå·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†: {censored_pdf.name}")
            input_queue.task_done()
            continue

        if not origin_pdf.exists():
            msg.error = f"åŸå§‹ PDF æ–‡ä»¶ä¸å­˜åœ¨: {origin_pdf}"
            logger.error(f"âŒ æ¶‚ç™½å¤±è´¥: {msg.error}")
            input_queue.task_done()
            continue

        if not translated_json or not translated_json.exists():
            msg.error = f"å¶å—æ–‡ä»¶ä¸å­˜åœ¨: {translated_json}"
            logger.error(f"âŒ æ¶‚ç™½å¤±è´¥: {msg.translated_json}")
            input_queue.task_done()
            continue

        try:
            loop = asyncio.get_running_loop()
            result = await loop.run_in_executor(
                None,
                generate_censored_pdf,
                translated_json,
                origin_pdf,
                censored_pdf
            )

            if result["success"] and censored_pdf.exists():
                msg.censored_pdf_path = censored_pdf
                await output_queue.put(msg)
                logger.info(f"ğŸ©¹ æ¶‚ç™½å®Œæˆ: {censored_pdf.name}")
            else:
                msg.error = f"æ¶‚ç™½å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                logger.error(f"âŒ æ¶‚ç™½å¤±è´¥: {msg.error}")

        except Exception as e:
            msg.error = f"æ¶‚ç™½è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}"
            logger.error(f"âŒ æ¶‚ç™½å¼‚å¸¸: {msg.error}")

        input_queue.task_done()

    await output_queue.put(None)
    logger.info("âœ… æ¶‚ç™½å¤„ç†é˜¶æ®µå®Œæˆ")


async def _render_single_html_async(translated_json: Path, html_output: Path) -> bool:
    """å¼‚æ­¥åŒ…è£… HTML æ¸²æŸ“"""
    loop = asyncio.get_running_loop()
    try:
        # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥çš„æ˜¯å‡½æ•° + å‚æ•°ï¼Œä¸æ˜¯è°ƒç”¨ç»“æœ
        result = await loop.run_in_executor(
            None,
            render_json_to_html,  # æ¥è‡ª json_to_html_renderer
            str(translated_json),
            str(html_output)
        )
        return result.get("success", False)
    except Exception as e:
        logger.error(f"âŒ å¼‚æ­¥æ¸²æŸ“å¼‚å¸¸: {e}")
        return False


async def stage_html_renderer(
    input_queue: asyncio.Queue,
    output_queue: asyncio.Queue,
    kwargs: dict
):
    end_signal_received = False
    
    while not end_signal_received:
        msg: PipelineMessage = await input_queue.get()
        if msg is None:
            input_queue.task_done()
            end_signal_received = True
            break

        if msg.error:
            input_queue.task_done()
            continue

        try:
            # === ã€æ–°å¢ã€‘åœ¨æœ€å¼€å§‹æ£€æŸ¥æœ€ç»ˆ PDF æ˜¯å¦å·²å­˜åœ¨ ===
            html_dir = msg.translated_path.parent / "images"
            final_pdf_path = html_dir / f"{msg.chunk_stem}_rendered_translate_final.pdf"

            if final_pdf_path.exists():
                logger.info(f"ğŸ–¨ï¸ æœ€ç»ˆPDFå·²å­˜åœ¨ï¼Œå®Œå…¨è·³è¿‡å¤„ç†: {final_pdf_path.name}")
                msg.pdf_path = final_pdf_path
                await output_queue.put(msg)
                input_queue.task_done()
                continue

            # â€”â€”â€”â€”â€”â€” ä»¥ä¸‹ä¸ºåŸæœ‰é€»è¾‘ï¼ˆä»…å½“æœ€ç»ˆ PDF ä¸å­˜åœ¨æ—¶æ‰æ‰§è¡Œï¼‰ â€”â€”â€”â€”â€”â€”

            html_dir = msg.translated_path.parent / "images"
            html_dir.mkdir(exist_ok=True)
            html_file = html_dir / f"{msg.chunk_stem}_rendered.html"

            # æ¸²æŸ“ HTMLï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if html_file.exists():
                logger.info(f"ğŸ“„ HTML å·²å­˜åœ¨ï¼Œè·³è¿‡æ¸²æŸ“: {html_file.name}")
                msg.html_path = html_file
            else:
                if not await _render_single_html_async(msg.translated_path, html_file):
                    msg.error = f"HTML æ¸²æŸ“å¤±è´¥: {html_file}"
                    logger.error(f"âŒ HTML æ¸²æŸ“å¤±è´¥: {msg.error}")
                    input_queue.task_done()
                    continue
                msg.html_path = html_file
                logger.info(f"ğŸ¨ HTML æ¸²æŸ“å®Œæˆ: {html_file.name}")

            # å‡†å¤‡æ¶‚ç™½ PDF è·¯å¾„
            censored_pdf_path_str = ""
            if msg.censored_pdf_path and msg.censored_pdf_path.exists():
                censored_pdf_path_str = str(msg.censored_pdf_path)
                logger.debug(f"ğŸ“ æ£€æµ‹åˆ°æ¶‚ç™½PDFï¼Œå°†ç”¨äºåˆå¹¶: {msg.censored_pdf_path.name}")
            else:
                logger.warning(f"ğŸŸ¡ æœªæ‰¾åˆ°æ¶‚ç™½PDFæ–‡ä»¶ï¼Œå°†è·³è¿‡åˆå¹¶: {msg.censored_pdf_path}")

            # è½¬æ¢ HTML ä¸º PDFï¼ˆå«åˆå¹¶ï¼‰
            pdf_result = await convert_single_html_to_pdf(
                html_file_path=str(html_file),
                censored_pdf_path=censored_pdf_path_str,
                prefer_css_page_size=kwargs.get("pdf_prefer_css_page_size", True),
                print_background=kwargs.get("print_background", True),
                scale=kwargs.get("pdf_scale", 1.0),
                stability_timeout=kwargs.get("stability_timeout", 10000),
                page_stable_check_interval=kwargs.get("page_stable_check_interval", 300),
                margin=kwargs.get("pdf_margin", {}),
            )

            if pdf_result["success"] and pdf_result["converted"]:
                final_pdf_path = Path(pdf_result["converted"][0])
                
                # å‹ç¼© PDF
                loop = asyncio.get_running_loop()
                compression_success = await loop.run_in_executor(
                    None, compress_pdf_structure_only, final_pdf_path
                )
                if not compression_success:
                    msg.error = "PDF å‹ç¼©å¤±è´¥"
                    logger.error(f"âŒ PDF å‹ç¼©å¤±è´¥: {final_pdf_path.name}")
                    input_queue.task_done()
                    continue
                
                msg.pdf_path = final_pdf_path
                await output_queue.put(msg)
                logger.info(f"ğŸ–¨ï¸âœ… æœ€ç»ˆPDFç”Ÿæˆå®Œæˆï¼ˆå«æ¶‚ç™½åˆå¹¶ï¼‰: {final_pdf_path.name}")
            else:
                error_msg = pdf_result.get("error", "æœªçŸ¥é”™è¯¯")
                msg.error = f"HTMLâ†’PDF è½¬æ¢å¤±è´¥: {error_msg}"
                logger.error(f"âŒ è½¬æ¢å¤±è´¥: {msg.error}")

        except Exception as e:
            msg.error = f"HTMLæ¸²æŸ“æˆ–PDFè½¬æ¢å¼‚å¸¸: {e}"
            logger.exception(f"âŒ å¤„ç†å¤±è´¥: {msg.chunk_path.name} | {e}")

        input_queue.task_done()

    await output_queue.put(None)
    logger.info("âœ… HTMLæ¸²æŸ“å’ŒPDFè½¬æ¢é˜¶æ®µå®Œæˆ")


async def stage_final_merger(
    input_queue: asyncio.Queue,
    final_output_dir: Path,
    pdf_stem: str
) -> Optional[Path]:
    """
    Stage 7: åˆå¹¶æ‰€æœ‰æœ€ç»ˆ PDFï¼ˆå‹ç¼©ç”±åˆå¹¶å‡½æ•°å†…éƒ¨å®Œæˆï¼‰
    """
    pdf_paths = []
    end_signal_received = False
    
    while not end_signal_received:
        msg = await input_queue.get()
        if msg is None:
            input_queue.task_done()
            end_signal_received = True
            break
        if msg.pdf_path and msg.pdf_path.exists():
            pdf_paths.append(msg.pdf_path)
        input_queue.task_done()

    # æŒ‰åç§°æ’åºç¡®ä¿é¡ºåº
    pdf_paths.sort(key=lambda p: p.name)

    final_pdf = final_output_dir / f"merged_{pdf_stem}.pdf"

    if not pdf_paths:
        logger.warning("âš ï¸ æ—  PDF æ–‡ä»¶å¯åˆå¹¶")
        return None

    # âœ… åˆå¹¶ PDFï¼ˆå†…éƒ¨å·²åŒ…å«å‹ç¼©ï¼‰
    result = merge_all_final_pdfs(
        file_list=[str(p) for p in pdf_paths],
        output_path=str(final_pdf)
    )

    if not result["success"]:
        logger.error(f"âŒ åˆå¹¶å¤±è´¥: {result['error']}")
        return None

    logger.success(f"ğŸ‰ æœ€ç»ˆåˆå¹¶ä¸å‹ç¼©å®Œæˆ: {final_pdf}")
    return final_pdf


async def translate_image_pdf(
    pdf_path: str,
    output_dir: str,
    target_lang: str,
    api_key: str = None,
    model_name: str = None,
    base_url: str = None,
    final_output_dir: str = None,
    max_concurrent_translate: int = 10,
    mineru_api_key = None,
    mineru_base_url= None,
    pdf_type: str = "txt",
    chunk_size: int = 25,
    max_concurrent_mineru: int = 1,
    cleanup_workdir: bool = False,  
    **kwargs
):
    """
    ä¸»å…¥å£ï¼šå¯åŠ¨å®Œå…¨è§£è€¦çš„æµæ°´çº¿ã€‚
    """
    pdf_path = Path(pdf_path).resolve()
    if not pdf_path.exists():
        return {"success": False, "error": f"PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}"}

    project_root = Path(__file__).parent.parent.resolve()
    workdir = (project_root / "workdir" / pdf_path.stem).resolve()
    workdir.mkdir(parents=True, exist_ok=True)

    final_output_path_obj = Path(final_output_dir or output_dir).resolve()
    final_output_path_obj.mkdir(parents=True, exist_ok=True)

    logger.info(f"ğŸ“„ å¼€å§‹å¤„ç† PDF: {pdf_path.name}")
    logger.info(f"âš™ï¸ ä½¿ç”¨æ¨¡å¼: {pdf_type}")

    # === é˜Ÿåˆ—å®šä¹‰ ===
    q_splitter_to_mineru = asyncio.Queue()
    q_mineru_to_leaf = asyncio.Queue()
    q_leaf_to_translate = asyncio.Queue()
    q_translate_to_blur = asyncio.Queue()   # æ–°å¢ï¼šç¿»è¯‘ â†’ æ¶‚ç™½
    q_blur_to_html = asyncio.Queue()        # æ–°å¢ï¼šæ¶‚ç™½ â†’ HTML æ¸²æŸ“
    q_html_to_pdf = asyncio.Queue()
    q_pdf_to_merge = asyncio.Queue()

    # === å¯åŠ¨å„é˜¶æ®µä»»åŠ¡ ===
    tasks = [
        asyncio.create_task(stage_splitter(pdf_path, workdir, chunk_size, q_splitter_to_mineru, pdf_type)),
        asyncio.create_task(stage_mineru_processor(q_splitter_to_mineru, q_mineru_to_leaf, workdir / "mineru_results", pdf_type, max_concurrent_mineru, mineru_api_key, mineru_base_url)),
        asyncio.create_task(stage_leaf_extractor(q_mineru_to_leaf, q_leaf_to_translate, pdf_type)),
        asyncio.create_task(stage_translator(q_leaf_to_translate, q_translate_to_blur, target_lang, api_key, base_url, model_name, max_concurrent_translate)),
        asyncio.create_task(stage_blur_processor(q_translate_to_blur, q_blur_to_html)),
        asyncio.create_task(stage_html_renderer(q_blur_to_html, q_html_to_pdf, kwargs)),
        asyncio.create_task(stage_final_merger(q_html_to_pdf, final_output_path_obj, pdf_path.stem)),  # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„é˜Ÿåˆ—
    ]

    try:
        # === ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ ===
        await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ£€æŸ¥åˆå¹¶ä»»åŠ¡çš„ç»“æœ
        merge_task = tasks[-1]  # æœ€åä¸€ä¸ªä»»åŠ¡æ˜¯åˆå¹¶ä»»åŠ¡
        if merge_task.done() and not merge_task.cancelled():
            final_pdf_path = merge_task.result()
        else:
            final_pdf_path = None

        # åˆ¤æ–­æ˜¯å¦çœŸæ­£æˆåŠŸ
        if final_pdf_path and final_pdf_path.exists():
            # âœ… æˆåŠŸï¼šæ ¹æ® cleanup_workdir å†³å®šæ˜¯å¦æ¸…ç†å·¥ä½œåŒº
            if cleanup_workdir:
                try:
                    import shutil
                    if workdir.exists():
                        shutil.rmtree(workdir)
                        logger.info(f"ğŸ§¹ å·¥ä½œåŒºå·²æ¸…é™¤: {workdir}")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¸…ç†å·¥ä½œåŒºå¤±è´¥ï¼ˆä½†æµç¨‹å·²æˆåŠŸï¼‰: {e}")
            else:
                logger.info(f"ğŸ” è°ƒè¯•æ¨¡å¼ï¼šä¿ç•™å·¥ä½œåŒº {workdir}")

            return {
                "success": True,
                "output_path": str(final_pdf_path),
                "merged_pdf_path": str(final_pdf_path),
                "message": "Pipeline completed successfully."
            }
        else:
            # âŒ åˆå¹¶æœªç”Ÿæˆæ–‡ä»¶ï¼Œè§†ä¸ºå¤±è´¥ï¼Œä¸æ¸…ç†
            return {
                "success": False,
                "output_path": "",
                "error": "åˆå¹¶å¤±è´¥æˆ–æœ€ç»ˆæ–‡ä»¶æœªç”Ÿæˆã€‚"
            }
            
    except Exception as e:
        logger.error(f"Pipeline æ‰§è¡Œå¼‚å¸¸: {e}")
        # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
        for task in tasks:
            if not task.done():
                task.cancel()
        # âŒ å¼‚å¸¸è§†ä¸ºå¤±è´¥ï¼Œä¸æ¸…ç†å·¥ä½œåŒº
        return {"success": False, "error": str(e)}